{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일명에 0,1,2중 1이 들어가지 않은 파일 제외하고 데이터 출력\n",
    "(ex. kopo_product_volume0, kopo_product_volume1, kopo_product_volume2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataSum = []\n",
    "for i in range(0,3):\n",
    "    if (i == 1):\n",
    "        pass\n",
    "    else:\n",
    "        ds = pd.read_csv(\"../dataset/kopo_product_volume\" + str(i) + \".csv\")\n",
    "        dataSum.append(ds)\n",
    "dataSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 깃허브에서 코드를 읽어오고 데이터의 type까지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "indata = pd.read_csv(\"https://raw.githubusercontent.com/hyokwan/python-lecture/master/dataset/customerdata.csv\")\n",
    "\n",
    "type(indata) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한글이 포함된 파일을 불러오게 되면 오류가 생김 \n",
    "#  그래서 아래와 같이 encoding=\"ms949\"로 해준다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(targetUrl, encoding=\"ms949\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * 파이썬에서 데이터를 불러와 저장을 하게 되면 자동으로 인덱스 (0,1,2,3 행)가 들어간다.\n",
    " * 그래서 index = False 해주면 인덱스는 포함되지 않고 불러올 수 있다. \n",
    "\n",
    "\n",
    " * 데이터 특정 칼럼명 바꾸기\n",
    " * indata.rename(columns = {\"salesid\": \"sid\",\n",
    "                              \"salesnme\": \"sname\"})\n",
    "\n",
    "\n",
    " * 데이터 분류를 , 와 ; 가아닌 |로 해서 구분을 지었다면  데이터 불러올때 sep = \"|\"으로 해줘야한다.\n",
    "(ex. pd.read_csv(\"../dataset/test.csv\", sep= \"|\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas 패키지 불러오기\n",
    "import pandas as pd\n",
    " \n",
    "# CSV 파일을 읽어 Data Frame 변수에 저장하기\n",
    "customerData = pd.read_csv(\"../dataset/customerdata.csv\")\n",
    "\n",
    "\n",
    "# 컬럼명 변경\n",
    "customerData.columns = [\"custid\",\"avgprice\",\"emi\",\\\n",
    "                        \"devicecount\",\"productage\",\"cstype\"]\n",
    "\n",
    "# CSV 파일로 저장\n",
    "#customerData.to_csv(\"../dataset/customerdata_out.csv\", index=False)\n",
    "\n",
    "# 데이터 변수에 .head()가 들어가면 데이터의 상위 (5줄)만 출력하게 된다.\n",
    "customerData.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# postgres서버에서 데이터를 query형식으로 불러와 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine \n",
    "\n",
    "engine= create_engine(\"postgresql://postgres:postgres@127.0.0.1:5432/postgres\")\n",
    "dataFrame = pd.read_sql_query(\"SELECT * FROM kopo_product_volume\", engine)\n",
    "dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터를 불러와 상단 5줄만 확인한 후 \n",
    "#  다른 이름으로 csv파일 저장해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./dataset/kopo_customerdata.csv\")\n",
    "data.head()\n",
    "data.to_csv(\"./test1.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터를 불러와 컬럼명 변경 후 csv파일로 이름을 재정의 해준 후 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "indata = pd.read_csv(\"../dataset/customerData.csv\")\n",
    "\n",
    "indata.columns = [\"custid\",\"avgprice\",\"emi\",\"devicecount\",\"productage\",\"custtype\"]\n",
    "indata.to_csv(\"../dataset/customerdata_out.csv\", index = False)\n",
    "indata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# postgres 서버 접속하여 query로 데이터를 불러오기 \n",
    "* 엔진 접속시 서버종류, ID,PW, 서버주소,포트번호, 데이터베이스명을 순으로 기입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"postgresql://postgres:postgres@127.0.0.1:5432/postgres\")\n",
    "data = pd.read_sql_query(\"select * from kopo_product_volume\",engine)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# postgres 서버에서 데이터를 불러와 컬럼명을 변경하고 \n",
    "# mariadb 서버에 파일명을 변경해주고 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# aws 서버에 접속\n",
    "# mariadb 서버에 접속 (이 서버에 파일을 저장해주기 위함)\n",
    "aws_engine = create_engine(\"postgresql://haiteam:haiteam@www.hadoopkorea.com:5432/postgres\") \n",
    "madb_engine = create_engine(\"mysql+pymysql://kopo:kopo@www.hadoopkorea.com:3306/kopo\") \n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_sql_query (\"select * from kopo_product_volume\", aws_engine) \n",
    "\n",
    "# 컬럼명 대문자로 변경 (기존 파일은 소문자로 저장이 되어있었음)\n",
    "data.columns = [\"ID\",\"PG\",\"YEARWEEK\",\"QTY\"] \n",
    "\n",
    "# 파일명 변경\n",
    "resultname = \"kopo_product_volume_오성훈\" \n",
    "\n",
    "# madb_engine에 파일 업로드\n",
    "data.to_sql(name = resultname,con =madb_engine,index = False,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# postgres서버에서 데이터 중 ST0001, \n",
    "# mariadb서버에서는 ST00002을 찾아 병합해주고난 후 \n",
    "# csv파일로 저장해주기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# postgres서버에서 데이터 중 ST0001, mariadb서버에서는 ST00002을 찾아 병합해주고난 후 csv파일로 저장해주기 #############\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# postgres,mariadb 서버 엔진 생성 \n",
    "post_engine = create_engine(\"postgresql://haiteam:haiteam@www.hadoopkorea.com:5432/postgres\")\n",
    "madb_engine = create_engine(\"mysql+pymysql://kopo:kopo@www.hadoopkorea.com:3306/kopo\")\n",
    "\n",
    "# post와 maria에서 가져올 데이터 변수 지정\n",
    "pdata =  pd.read_sql_query (\"select * from kopo_product_volume_st01\", post_engine)\n",
    "mdata = pd.read_sql_query (\"select * from kopo_product_volume_st02\", madb_engine)\n",
    "\n",
    "\n",
    "# 데이터 병합\n",
    "answer = pd.concat([pdata, mdata], axis= 0)\n",
    "answer\n",
    "# postgres에 csv파일로 저장\n",
    "# answer.to_csv(\"name = kopo_product_volume, con = post_engine, if_exists = 'replace', index=False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웹 크롤링 \n",
    "* [find 활용] sparkkorea.com 사이트내 퀴즈 페이지 에서\n",
    "스파크 퀴즈  퀴즈이름 및 링크정보를 스크랩 하세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 생성\n",
    "import requests, bs4\n",
    "import pandas as pd\n",
    "\n",
    "# 웹페이지 요청\n",
    "resp = requests.get(url = \"https://sparkkorea.com/퀴즈\")\n",
    "# 웹페이즈 텍스트 문자로 읽어오기\n",
    "html = resp.text\n",
    "\n",
    "# BeautifulSoup로 해당 사이트 보기 좋게 읽어오기 \n",
    "bs = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# \"a\" 문자 찾기\n",
    "atag = bs.find(name = \"a\")\n",
    "# \"a\" 문자 모두 찾기\n",
    "atags = bs.findAll(name = \"a\")\n",
    "\n",
    "\n",
    "# div태그에서 속성정보 ({\"id\":\"id_spark_quiz\"})로 찾기\n",
    "divtags = bs.find(name = \"div\",\n",
    "               attrs = {\"id\":\"id_spark_quiz\"})\n",
    "\n",
    "# div태그의 간추린 데이터에서 \"a\" 해당 데이터 찾기\n",
    "ats = divtags.findAll(name = \"a\")\n",
    "\n",
    "# 간추린 데이터에서 링크데이터와 문자 데이터 나누기\n",
    "link = ats[0].attrs[\"href\"]\n",
    "title = ats[0].text\n",
    "\n",
    "# 리스트 변수 생성\n",
    "linklist = []\n",
    "ttlelist = []\n",
    "\n",
    "# for문에 필요한 데이터 길이 변수 생성\n",
    "atslen = len(ats)\n",
    "\n",
    "# 링크 데이터와 문자 데이터를 합칠 배열 생성\n",
    "rowlist = []\n",
    "\n",
    "# for문을 이용하여 rowlist에 담을 데이터들 리스트에 넣기\n",
    "for i in range(0, atslen):\n",
    "    eachtitle = ats[i].attrs[\"href\"]\n",
    "    eachtext = ats[i].text\n",
    "    \n",
    "    rowlist.append( [ eachtitle, eachtext])\n",
    "    \n",
    "# 데이터 시각화 해주기    \n",
    "pd.DataFrame(rowlist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
